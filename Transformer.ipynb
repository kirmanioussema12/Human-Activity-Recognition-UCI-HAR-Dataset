{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:61: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(path, delim_whitespace=True, header=None).values.flatten()\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\1234582450.py:61: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(path, delim_whitespace=True, header=None).values.flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X: (7352, 128, 9)  Test X: (2947, 128, 9)\n",
      "Classes (encoded): [0, 1, 2, 3, 4, 5]\n",
      "Split -> Train: (5881, 128, 9)  Val: (1471, 128, 9)\n",
      "After augmentation -> Train: (6881, 128, 9)  Val: (1471, 128, 9)\n",
      "Test for evaluation: (2947, 128, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m640\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m66,368\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m8,256\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m8,256\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m8,320\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │        \u001b[38;5;34m774\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">176,134</span> (688.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m176,134\u001b[0m (688.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">176,134</span> (688.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m176,134\u001b[0m (688.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 257ms/step - accuracy: 0.4531 - loss: 1.3467 - val_accuracy: 0.7458 - val_loss: 0.6813 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 245ms/step - accuracy: 0.7556 - loss: 0.6688 - val_accuracy: 0.8668 - val_loss: 0.4562 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 380ms/step - accuracy: 0.8364 - loss: 0.4795 - val_accuracy: 0.9137 - val_loss: 0.2647 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 385ms/step - accuracy: 0.9038 - loss: 0.3102 - val_accuracy: 0.9361 - val_loss: 0.1687 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 195ms/step - accuracy: 0.9198 - loss: 0.2234 - val_accuracy: 0.9483 - val_loss: 0.1374 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 174ms/step - accuracy: 0.9306 - loss: 0.1883 - val_accuracy: 0.9517 - val_loss: 0.1238 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 193ms/step - accuracy: 0.9339 - loss: 0.1771 - val_accuracy: 0.9531 - val_loss: 0.1144 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 172ms/step - accuracy: 0.9322 - loss: 0.1706 - val_accuracy: 0.9579 - val_loss: 0.1073 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 168ms/step - accuracy: 0.9404 - loss: 0.1571 - val_accuracy: 0.9599 - val_loss: 0.1023 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 170ms/step - accuracy: 0.9420 - loss: 0.1533 - val_accuracy: 0.9640 - val_loss: 0.0987 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 165ms/step - accuracy: 0.9421 - loss: 0.1465 - val_accuracy: 0.9626 - val_loss: 0.0963 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 166ms/step - accuracy: 0.9431 - loss: 0.1441 - val_accuracy: 0.9619 - val_loss: 0.0953 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 167ms/step - accuracy: 0.9442 - loss: 0.1361 - val_accuracy: 0.9606 - val_loss: 0.0947 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 165ms/step - accuracy: 0.9450 - loss: 0.1324 - val_accuracy: 0.9640 - val_loss: 0.0921 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 166ms/step - accuracy: 0.9451 - loss: 0.1332 - val_accuracy: 0.9646 - val_loss: 0.0923 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 167ms/step - accuracy: 0.9482 - loss: 0.1273 - val_accuracy: 0.9606 - val_loss: 0.0943 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 166ms/step - accuracy: 0.9493 - loss: 0.1241 - val_accuracy: 0.9667 - val_loss: 0.0912 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 167ms/step - accuracy: 0.9520 - loss: 0.1157 - val_accuracy: 0.9701 - val_loss: 0.0839 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 170ms/step - accuracy: 0.9538 - loss: 0.1164 - val_accuracy: 0.9735 - val_loss: 0.0795 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 169ms/step - accuracy: 0.9556 - loss: 0.1083 - val_accuracy: 0.9708 - val_loss: 0.0777 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 166ms/step - accuracy: 0.9589 - loss: 0.1029 - val_accuracy: 0.9769 - val_loss: 0.0720 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 167ms/step - accuracy: 0.9599 - loss: 0.1018 - val_accuracy: 0.9728 - val_loss: 0.0744 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 175ms/step - accuracy: 0.9616 - loss: 0.0979 - val_accuracy: 0.9748 - val_loss: 0.0656 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 172ms/step - accuracy: 0.9623 - loss: 0.0964 - val_accuracy: 0.9735 - val_loss: 0.0649 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 167ms/step - accuracy: 0.9610 - loss: 0.0924 - val_accuracy: 0.9755 - val_loss: 0.0610 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 168ms/step - accuracy: 0.9652 - loss: 0.0825 - val_accuracy: 0.9769 - val_loss: 0.0596 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 166ms/step - accuracy: 0.9648 - loss: 0.0846 - val_accuracy: 0.9742 - val_loss: 0.0581 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 166ms/step - accuracy: 0.9655 - loss: 0.0816 - val_accuracy: 0.9742 - val_loss: 0.0553 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 167ms/step - accuracy: 0.9694 - loss: 0.0745 - val_accuracy: 0.9762 - val_loss: 0.0515 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - accuracy: 0.9720 - loss: 0.0690 - val_accuracy: 0.9789 - val_loss: 0.0487 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 169ms/step - accuracy: 0.9709 - loss: 0.0696 - val_accuracy: 0.9776 - val_loss: 0.0511 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 166ms/step - accuracy: 0.9732 - loss: 0.0645 - val_accuracy: 0.9796 - val_loss: 0.0487 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 170ms/step - accuracy: 0.9765 - loss: 0.0631 - val_accuracy: 0.9803 - val_loss: 0.0474 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 167ms/step - accuracy: 0.9730 - loss: 0.0621 - val_accuracy: 0.9796 - val_loss: 0.0482 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 167ms/step - accuracy: 0.9770 - loss: 0.0568 - val_accuracy: 0.9803 - val_loss: 0.0469 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 169ms/step - accuracy: 0.9799 - loss: 0.0566 - val_accuracy: 0.9810 - val_loss: 0.0491 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 169ms/step - accuracy: 0.9799 - loss: 0.0537 - val_accuracy: 0.9810 - val_loss: 0.0510 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - accuracy: 0.9771 - loss: 0.0571 - val_accuracy: 0.9803 - val_loss: 0.0480 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 194ms/step - accuracy: 0.9795 - loss: 0.0524 - val_accuracy: 0.9748 - val_loss: 0.0555 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 227ms/step - accuracy: 0.9776 - loss: 0.0526 - val_accuracy: 0.9803 - val_loss: 0.0476 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 221ms/step - accuracy: 0.9785 - loss: 0.0532 - val_accuracy: 0.9837 - val_loss: 0.0446 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 188ms/step - accuracy: 0.9803 - loss: 0.0495 - val_accuracy: 0.9816 - val_loss: 0.0461 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 202ms/step - accuracy: 0.9831 - loss: 0.0466 - val_accuracy: 0.9782 - val_loss: 0.0519 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 211ms/step - accuracy: 0.9817 - loss: 0.0462 - val_accuracy: 0.9796 - val_loss: 0.0502 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 199ms/step - accuracy: 0.9820 - loss: 0.0478 - val_accuracy: 0.9823 - val_loss: 0.0416 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 194ms/step - accuracy: 0.9808 - loss: 0.0451 - val_accuracy: 0.9796 - val_loss: 0.0465 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 220ms/step - accuracy: 0.9822 - loss: 0.0416 - val_accuracy: 0.9782 - val_loss: 0.0495 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 209ms/step - accuracy: 0.9830 - loss: 0.0453 - val_accuracy: 0.9823 - val_loss: 0.0409 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 184ms/step - accuracy: 0.9850 - loss: 0.0382 - val_accuracy: 0.9803 - val_loss: 0.0508 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 186ms/step - accuracy: 0.9825 - loss: 0.0437 - val_accuracy: 0.9857 - val_loss: 0.0393 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 188ms/step - accuracy: 0.9845 - loss: 0.0377 - val_accuracy: 0.9810 - val_loss: 0.0504 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 189ms/step - accuracy: 0.9837 - loss: 0.0397 - val_accuracy: 0.9830 - val_loss: 0.0437 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 183ms/step - accuracy: 0.9832 - loss: 0.0389 - val_accuracy: 0.9844 - val_loss: 0.0394 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 185ms/step - accuracy: 0.9856 - loss: 0.0371 - val_accuracy: 0.9830 - val_loss: 0.0420 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 183ms/step - accuracy: 0.9842 - loss: 0.0355 - val_accuracy: 0.9837 - val_loss: 0.0385 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 184ms/step - accuracy: 0.9852 - loss: 0.0347 - val_accuracy: 0.9810 - val_loss: 0.0428 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 189ms/step - accuracy: 0.9848 - loss: 0.0342 - val_accuracy: 0.9823 - val_loss: 0.0465 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 184ms/step - accuracy: 0.9862 - loss: 0.0362 - val_accuracy: 0.9830 - val_loss: 0.0412 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 185ms/step - accuracy: 0.9861 - loss: 0.0321 - val_accuracy: 0.9837 - val_loss: 0.0399 - learning_rate: 1.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 186ms/step - accuracy: 0.9866 - loss: 0.0340 - val_accuracy: 0.9823 - val_loss: 0.0434 - learning_rate: 1.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.9874 - loss: 0.0321\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 185ms/step - accuracy: 0.9874 - loss: 0.0321 - val_accuracy: 0.9816 - val_loss: 0.0446 - learning_rate: 1.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 189ms/step - accuracy: 0.9896 - loss: 0.0275 - val_accuracy: 0.9884 - val_loss: 0.0367 - learning_rate: 5.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 190ms/step - accuracy: 0.9901 - loss: 0.0250 - val_accuracy: 0.9850 - val_loss: 0.0414 - learning_rate: 5.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 185ms/step - accuracy: 0.9888 - loss: 0.0272 - val_accuracy: 0.9837 - val_loss: 0.0394 - learning_rate: 5.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 201ms/step - accuracy: 0.9894 - loss: 0.0252 - val_accuracy: 0.9864 - val_loss: 0.0366 - learning_rate: 5.0000e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 392ms/step - accuracy: 0.9911 - loss: 0.0248 - val_accuracy: 0.9884 - val_loss: 0.0350 - learning_rate: 5.0000e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 450ms/step - accuracy: 0.9903 - loss: 0.0241 - val_accuracy: 0.9878 - val_loss: 0.0368 - learning_rate: 5.0000e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 314ms/step - accuracy: 0.9903 - loss: 0.0241 - val_accuracy: 0.9857 - val_loss: 0.0372 - learning_rate: 5.0000e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 198ms/step - accuracy: 0.9902 - loss: 0.0294 - val_accuracy: 0.9884 - val_loss: 0.0373 - learning_rate: 5.0000e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 190ms/step - accuracy: 0.9916 - loss: 0.0225 - val_accuracy: 0.9864 - val_loss: 0.0374 - learning_rate: 5.0000e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 183ms/step - accuracy: 0.9901 - loss: 0.0242 - val_accuracy: 0.9878 - val_loss: 0.0372 - learning_rate: 5.0000e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9916 - loss: 0.0225\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 185ms/step - accuracy: 0.9916 - loss: 0.0225 - val_accuracy: 0.9837 - val_loss: 0.0398 - learning_rate: 5.0000e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 183ms/step - accuracy: 0.9891 - loss: 0.0269 - val_accuracy: 0.9905 - val_loss: 0.0356 - learning_rate: 2.5000e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 184ms/step - accuracy: 0.9914 - loss: 0.0234 - val_accuracy: 0.9884 - val_loss: 0.0366 - learning_rate: 2.5000e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 224ms/step - accuracy: 0.9920 - loss: 0.0205 - val_accuracy: 0.9898 - val_loss: 0.0368 - learning_rate: 2.5000e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 224ms/step - accuracy: 0.9902 - loss: 0.0231 - val_accuracy: 0.9884 - val_loss: 0.0357 - learning_rate: 2.5000e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 225ms/step - accuracy: 0.9925 - loss: 0.0191 - val_accuracy: 0.9871 - val_loss: 0.0365 - learning_rate: 2.5000e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9911 - loss: 0.0220\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 192ms/step - accuracy: 0.9911 - loss: 0.0220 - val_accuracy: 0.9884 - val_loss: 0.0356 - learning_rate: 2.5000e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 187ms/step - accuracy: 0.9924 - loss: 0.0200 - val_accuracy: 0.9884 - val_loss: 0.0360 - learning_rate: 1.2500e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 190ms/step - accuracy: 0.9926 - loss: 0.0194 - val_accuracy: 0.9905 - val_loss: 0.0342 - learning_rate: 1.2500e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 213ms/step - accuracy: 0.9923 - loss: 0.0197 - val_accuracy: 0.9891 - val_loss: 0.0348 - learning_rate: 1.2500e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 191ms/step - accuracy: 0.9939 - loss: 0.0178 - val_accuracy: 0.9891 - val_loss: 0.0345 - learning_rate: 1.2500e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 191ms/step - accuracy: 0.9934 - loss: 0.0178 - val_accuracy: 0.9891 - val_loss: 0.0345 - learning_rate: 1.2500e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 190ms/step - accuracy: 0.9939 - loss: 0.0175 - val_accuracy: 0.9905 - val_loss: 0.0341 - learning_rate: 1.2500e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 194ms/step - accuracy: 0.9942 - loss: 0.0161 - val_accuracy: 0.9891 - val_loss: 0.0351 - learning_rate: 1.2500e-05\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "\n",
      "=== Validation ===\n",
      "Accuracy: 0.9905\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       245\n",
      "           2       1.00      1.00      1.00       215\n",
      "           3       1.00      1.00      1.00       197\n",
      "           4       0.96      0.98      0.97       257\n",
      "           5       0.99      0.96      0.97       275\n",
      "           6       1.00      1.00      1.00       282\n",
      "\n",
      "    accuracy                           0.99      1471\n",
      "   macro avg       0.99      0.99      0.99      1471\n",
      "weighted avg       0.99      0.99      0.99      1471\n",
      "\n",
      "Confusion Matrix:\n",
      "[[245   0   0   0   0   0]\n",
      " [  0 215   0   0   0   0]\n",
      " [  0   0 197   0   0   0]\n",
      " [  0   0   0 253   4   0]\n",
      " [  0   0   0  10 265   0]\n",
      " [  0   0   0   0   0 282]]\n",
      "\n",
      "=== Test ===\n",
      "Accuracy: 0.9220\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.86      0.90       496\n",
      "           2       0.93      0.92      0.93       471\n",
      "           3       0.85      0.96      0.90       420\n",
      "           4       0.91      0.86      0.89       491\n",
      "           5       0.88      0.92      0.90       532\n",
      "           6       1.00      1.00      1.00       537\n",
      "\n",
      "    accuracy                           0.92      2947\n",
      "   macro avg       0.92      0.92      0.92      2947\n",
      "weighted avg       0.92      0.92      0.92      2947\n",
      "\n",
      "Confusion Matrix:\n",
      "[[426  27  43   0   0   0]\n",
      " [  8 435  28   0   0   0]\n",
      " [ 12   4 404   0   0   0]\n",
      " [  0   0   0 424  67   0]\n",
      " [  0   0   0  41 491   0]\n",
      " [  0   0   0   0   0 537]]\n"
     ]
    }
   ],
   "source": [
    "# ===== Full Transformer HAR Training + Augmentation + Eval =====\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, LayerNormalization,\n",
    "    MultiHeadAttention, GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# -----------------------\n",
    "# Reproducibility\n",
    "# -----------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# -----------------------\n",
    "# Paths\n",
    "# -----------------------\n",
    "TRAIN_SIGNALS = r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\UCI HAR Dataset\\train\\Inertial Signals\\\\\"\n",
    "TEST_SIGNALS  = r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\UCI HAR Dataset\\test\\Inertial Signals\\\\\"\n",
    "TRAIN_LABELS  = r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\UCI HAR Dataset\\train\\y_train.txt\"\n",
    "TEST_LABELS   = r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\UCI HAR Dataset\\test\\y_test.txt\"\n",
    "\n",
    "# Option: evaluate on 50% of the official test set (set to False to keep all)\n",
    "REDUCE_TEST_BY_HALF = False\n",
    "\n",
    "# -----------------------\n",
    "# Data loading utilities\n",
    "# -----------------------\n",
    "def load_sensor_matrix(base_path: str, split: str):\n",
    "    \"\"\"\n",
    "    Load 9 Inertial Signals for a given split ('train' or 'test').\n",
    "    Returns array of shape (samples, 128, 9).\n",
    "    \"\"\"\n",
    "    suffix = f\"_{split}.txt\"\n",
    "    names = [\n",
    "        \"body_acc_x\", \"body_acc_y\", \"body_acc_z\",\n",
    "        \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\",\n",
    "        \"total_acc_x\", \"total_acc_y\", \"total_acc_z\",\n",
    "    ]\n",
    "    mats = []\n",
    "    for name in names:\n",
    "        fn = f\"{name}{suffix}\"\n",
    "        df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
    "        mats.append(df.values)  # (samples, 128)\n",
    "    X = np.stack(mats, axis=2)  # (samples, 128, 9)\n",
    "    return X\n",
    "\n",
    "def load_labels(path: str):\n",
    "    return pd.read_csv(path, delim_whitespace=True, header=None).values.flatten()\n",
    "\n",
    "# -----------------------\n",
    "# Load train & test\n",
    "# -----------------------\n",
    "X_train_full = load_sensor_matrix(TRAIN_SIGNALS, \"train\")\n",
    "y_train_full = load_labels(TRAIN_LABELS)\n",
    "\n",
    "X_test_full  = load_sensor_matrix(TEST_SIGNALS, \"test\")\n",
    "y_test_full  = load_labels(TEST_LABELS)\n",
    "\n",
    "print(\"Train X:\", X_train_full.shape, \" Test X:\", X_test_full.shape)\n",
    "\n",
    "# -----------------------\n",
    "# Label encode (fit on train only)\n",
    "# -----------------------\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_enc = label_encoder.fit_transform(y_train_full)\n",
    "y_test_enc  = label_encoder.transform(y_test_full)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(\"Classes (encoded):\", list(range(num_classes)))\n",
    "\n",
    "# -----------------------\n",
    "# Stratified Train/Val split (~20% val ≈ 1470 samples)\n",
    "# -----------------------\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_idx, val_idx = next(sss.split(X_train_full, y_train_enc))\n",
    "\n",
    "X_train, X_val = X_train_full[train_idx], X_train_full[val_idx]\n",
    "y_train, y_val = y_train_enc[train_idx], y_train_enc[val_idx]\n",
    "print(\"Split -> Train:\", X_train.shape, \" Val:\", X_val.shape)\n",
    "\n",
    "# -----------------------\n",
    "# Scale features (fit on TRAIN only, apply to VAL & TEST)\n",
    "# -----------------------\n",
    "def scale_by_feature(X_fit, X_list):\n",
    "    ns, t, f = X_fit.shape\n",
    "    scaler = StandardScaler()\n",
    "    X_fit_2d = X_fit.reshape(-1, f)\n",
    "    scaler.fit(X_fit_2d)\n",
    "    out = []\n",
    "    for X in X_list:\n",
    "        X2 = X.reshape(-1, f)\n",
    "        Xs = scaler.transform(X2).reshape(X.shape[0], t, f)\n",
    "        out.append(Xs)\n",
    "    return out\n",
    "\n",
    "X_train_scaled, X_val_scaled, X_test_scaled = scale_by_feature(X_train, [X_train, X_val, X_test_full])\n",
    "\n",
    "# -----------------------\n",
    "# Data augmentation: jitter classes 3 and 4 (+500 each)\n",
    "# -----------------------\n",
    "def jitter(samples, sigma=0.05):\n",
    "    return samples + np.random.normal(0, sigma, size=samples.shape)\n",
    "\n",
    "aug_X_list = []\n",
    "aug_y_list = []\n",
    "for cls in [0,1,2,3,4]:\n",
    "    cls_indices = np.where(y_train == cls)[0]\n",
    "    if len(cls_indices) == 0:\n",
    "        print(f\"Warning: class {cls} not present in training set; skipping augmentation.\")\n",
    "        continue\n",
    "    chosen = np.random.choice(cls_indices, size=500, replace=True)\n",
    "    jittered = jitter(X_train_scaled[chosen], sigma=0.05)\n",
    "    aug_X_list.append(jittered)\n",
    "    aug_y_list.append(np.full(jittered.shape[0], cls, dtype=y_train.dtype))\n",
    "\n",
    "if aug_X_list:\n",
    "    X_aug = np.vstack(aug_X_list)\n",
    "    y_aug = np.concatenate(aug_y_list)\n",
    "    X_train_final = np.vstack([X_train_scaled, X_aug])\n",
    "    y_train_final = np.concatenate([y_train, y_aug])\n",
    "else:\n",
    "    X_train_final, y_train_final = X_train_scaled, y_train\n",
    "\n",
    "print(\"After augmentation -> Train:\", X_train_final.shape, \" Val:\", X_val_scaled.shape)\n",
    "\n",
    "# -----------------------\n",
    "# (Optional) Reduce test by 50% (stratified)\n",
    "# -----------------------\n",
    "if REDUCE_TEST_BY_HALF:\n",
    "    sss_test = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=SEED)\n",
    "    keep_idx, _ = next(sss_test.split(X_test_scaled, y_test_enc))\n",
    "    X_test_eval = X_test_scaled[keep_idx]\n",
    "    y_test_eval = y_test_enc[keep_idx]\n",
    "else:\n",
    "    X_test_eval = X_test_scaled\n",
    "    y_test_eval = y_test_enc\n",
    "\n",
    "print(\"Test for evaluation:\", X_test_eval.shape)\n",
    "\n",
    "# -----------------------\n",
    "# Transformer model\n",
    "# -----------------------\n",
    "def build_transformer_model(input_shape, num_classes,\n",
    "                            embed_dim=64, num_heads=4, ff_dim=128,\n",
    "                            num_layers=2, dropout_rate=0.2, lr=1e-4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Linear projection to embedding space\n",
    "    x = Dense(embed_dim)(inputs)\n",
    "\n",
    "    # Stacked Transformer Encoder blocks\n",
    "    for _ in range(num_layers):\n",
    "        # Self-attention + residual\n",
    "        attn = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(x, x)\n",
    "        attn = Dropout(dropout_rate)(attn)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + attn)\n",
    "\n",
    "        # Feed-forward + residual\n",
    "        ffn = Dense(ff_dim, activation=\"relu\")(x)\n",
    "        ffn = Dense(embed_dim)(ffn)\n",
    "        ffn = Dropout(dropout_rate)(ffn)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + ffn)\n",
    "\n",
    "    # Sequence pooling\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Head\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "input_shape = (X_train_final.shape[1], X_train_final.shape[2])\n",
    "model = build_transformer_model(input_shape, num_classes,\n",
    "                                embed_dim=64, num_heads=4, ff_dim=128,\n",
    "                                num_layers=2, dropout_rate=0.3, lr=1e-4)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# -----------------------\n",
    "# Training\n",
    "# -----------------------\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_accuracy\", patience=12, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", patience=6, factor=0.5, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Evaluation (Validation & Test)\n",
    "# -----------------------\n",
    "def evaluate_split(name, X, y_true):\n",
    "    y_prob = model.predict(X, verbose=0)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[str(c) for c in label_encoder.classes_]))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "evaluate_split(\"Validation\", X_val_scaled, y_val)\n",
    "evaluate_split(\"Test\", X_test_eval, y_test_eval)\n",
    "\n",
    "# -----------------------\n",
    "# (Optional) Save model\n",
    "# -----------------------\n",
    "# model.save(r\"C:\\path\\to\\save\\har_transformer.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f48cc6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(r'C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\UCI HAR Dataset\\Models\\transformer_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "062d613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Test set: (1474, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Reduce test to exactly 1473 samples (stratified)\n",
    "# -----------------------\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "TARGET_TEST_SIZE = 1473\n",
    "sss_test = StratifiedShuffleSplit(n_splits=1, test_size=TARGET_TEST_SIZE, random_state=SEED)\n",
    "keep_idx, _ = next(sss_test.split(X_test_scaled, y_test_enc))\n",
    "\n",
    "X_test_eval = X_test_scaled[keep_idx]\n",
    "y_test_eval = y_test_enc[keep_idx]\n",
    "\n",
    "print(\"Reduced Test set:\", X_test_eval.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647770b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Validation ===\n",
      "Accuracy: 0.9905\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       245\n",
      "           2       1.00      1.00      1.00       215\n",
      "           3       1.00      1.00      1.00       197\n",
      "           4       0.96      0.98      0.97       257\n",
      "           5       0.99      0.96      0.97       275\n",
      "           6       1.00      1.00      1.00       282\n",
      "\n",
      "    accuracy                           0.99      1471\n",
      "   macro avg       0.99      0.99      0.99      1471\n",
      "weighted avg       0.99      0.99      0.99      1471\n",
      "\n",
      "Confusion Matrix:\n",
      "[[245   0   0   0   0   0]\n",
      " [  0 215   0   0   0   0]\n",
      " [  0   0 197   0   0   0]\n",
      " [  0   0   0 253   4   0]\n",
      " [  0   0   0  10 265   0]\n",
      " [  0   0   0   0   0 282]]\n",
      "\n",
      "=== Test ===\n",
      "Accuracy: 0.9369\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.89      0.92       248\n",
      "           2       0.95      0.93      0.94       235\n",
      "           3       0.88      0.98      0.93       210\n",
      "           4       0.92      0.90      0.91       246\n",
      "           5       0.91      0.92      0.92       266\n",
      "           6       1.00      1.00      1.00       269\n",
      "\n",
      "    accuracy                           0.94      1474\n",
      "   macro avg       0.94      0.94      0.94      1474\n",
      "weighted avg       0.94      0.94      0.94      1474\n",
      "\n",
      "Confusion Matrix:\n",
      "[[220  12  16   0   0   0]\n",
      " [  4 219  12   0   0   0]\n",
      " [  4   0 206   0   0   0]\n",
      " [  0   0   0 221  25   0]\n",
      " [  0   0   0  20 246   0]\n",
      " [  0   0   0   0   0 269]]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Reduce test to exactly 1473 samples (stratified)\n",
    "# -----------------------\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "TARGET_TEST_SIZE = 1473\n",
    "sss_test = StratifiedShuffleSplit(n_splits=1, test_size=TARGET_TEST_SIZE, random_state=SEED)\n",
    "keep_idx, _ = next(sss_test.split(X_test_scaled, y_test_enc))\n",
    "\n",
    "X_test_eval = X_test_scaled[keep_idx]\n",
    "y_test_eval = y_test_enc[keep_idx]\n",
    "\n",
    "print(\"Reduced Test set:\", X_test_eval.shape)\n",
    "\n",
    "def evaluate_split(name, X, y_true):\n",
    "    y_prob = model.predict(X, verbose=0)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[str(c) for c in label_encoder.classes_]))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "evaluate_split(\"Validation\", X_val_scaled, y_val)\n",
    "evaluate_split(\"Test\", X_test_eval, y_test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51aab387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:61: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(path, delim_whitespace=True, header=None).values.flatten()\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:55: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_19460\\2729547399.py:61: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  return pd.read_csv(path, delim_whitespace=True, header=None).values.flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X: (7352, 128, 9)  Test X: (2947, 128, 9)\n",
      "Classes (encoded): [0, 1, 2, 3, 4, 5]\n",
      "Split -> Train: (5881, 128, 9)  Val: (1471, 128, 9)\n",
      "After augmentation -> Train: (8381, 128, 9)  Val: (1471, 128, 9)\n",
      "Test for evaluation: (2947, 128, 9)\n",
      "Class weights: {0: np.float64(1.1318028359216745), 1: np.float64(1.2343151693667156), 2: np.float64(1.300387897595035), 3: np.float64(0.9135600610420754), 4: np.float64(0.8735668125912028), 5: np.float64(1.2416296296296296)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m640\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m66,368\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m8,256\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m8,256\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m128\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m8,320\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │        \u001b[38;5;34m774\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">176,134</span> (688.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m176,134\u001b[0m (688.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">176,134</span> (688.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m176,134\u001b[0m (688.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 180ms/step - accuracy: 0.4750 - loss: 1.3043 - val_accuracy: 0.8423 - val_loss: 0.5589 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 174ms/step - accuracy: 0.7897 - loss: 0.6200 - val_accuracy: 0.9069 - val_loss: 0.3034 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - accuracy: 0.8926 - loss: 0.3537 - val_accuracy: 0.9279 - val_loss: 0.1932 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 177ms/step - accuracy: 0.9257 - loss: 0.2308 - val_accuracy: 0.9415 - val_loss: 0.1447 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 179ms/step - accuracy: 0.9326 - loss: 0.1768 - val_accuracy: 0.9449 - val_loss: 0.1260 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.9425 - loss: 0.1582 - val_accuracy: 0.9511 - val_loss: 0.1140 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.9452 - loss: 0.1377 - val_accuracy: 0.9545 - val_loss: 0.1072 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 178ms/step - accuracy: 0.9471 - loss: 0.1314 - val_accuracy: 0.9565 - val_loss: 0.1035 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 179ms/step - accuracy: 0.9464 - loss: 0.1259 - val_accuracy: 0.9572 - val_loss: 0.1011 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 179ms/step - accuracy: 0.9484 - loss: 0.1246 - val_accuracy: 0.9579 - val_loss: 0.0988 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 183ms/step - accuracy: 0.9509 - loss: 0.1151 - val_accuracy: 0.9579 - val_loss: 0.0972 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.9497 - loss: 0.1177 - val_accuracy: 0.9579 - val_loss: 0.0958 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.9498 - loss: 0.1125 - val_accuracy: 0.9606 - val_loss: 0.0932 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 185ms/step - accuracy: 0.9535 - loss: 0.1121 - val_accuracy: 0.9626 - val_loss: 0.0903 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - accuracy: 0.9529 - loss: 0.1092 - val_accuracy: 0.9640 - val_loss: 0.0902 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 180ms/step - accuracy: 0.9550 - loss: 0.1028 - val_accuracy: 0.9640 - val_loss: 0.0893 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.9571 - loss: 0.1022 - val_accuracy: 0.9640 - val_loss: 0.0870 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.9566 - loss: 0.1007 - val_accuracy: 0.9646 - val_loss: 0.0833 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - accuracy: 0.9560 - loss: 0.1021 - val_accuracy: 0.9653 - val_loss: 0.0822 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 182ms/step - accuracy: 0.9612 - loss: 0.0974 - val_accuracy: 0.9674 - val_loss: 0.0809 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.9594 - loss: 0.0950 - val_accuracy: 0.9680 - val_loss: 0.0785 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 198ms/step - accuracy: 0.9595 - loss: 0.0900 - val_accuracy: 0.9680 - val_loss: 0.0759 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 186ms/step - accuracy: 0.9603 - loss: 0.0882 - val_accuracy: 0.9674 - val_loss: 0.0748 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 186ms/step - accuracy: 0.9614 - loss: 0.0859 - val_accuracy: 0.9694 - val_loss: 0.0707 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 189ms/step - accuracy: 0.9645 - loss: 0.0815 - val_accuracy: 0.9708 - val_loss: 0.0660 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.9646 - loss: 0.0781 - val_accuracy: 0.9701 - val_loss: 0.0670 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - accuracy: 0.9670 - loss: 0.0741 - val_accuracy: 0.9701 - val_loss: 0.0627 - learning_rate: 1.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.9693 - loss: 0.0698 - val_accuracy: 0.9748 - val_loss: 0.0611 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 186ms/step - accuracy: 0.9690 - loss: 0.0687 - val_accuracy: 0.9755 - val_loss: 0.0577 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 197ms/step - accuracy: 0.9706 - loss: 0.0665 - val_accuracy: 0.9748 - val_loss: 0.0547 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 186ms/step - accuracy: 0.9707 - loss: 0.0617 - val_accuracy: 0.9755 - val_loss: 0.0568 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 271ms/step - accuracy: 0.9728 - loss: 0.0609 - val_accuracy: 0.9769 - val_loss: 0.0563 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 399ms/step - accuracy: 0.9715 - loss: 0.0599 - val_accuracy: 0.9803 - val_loss: 0.0485 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 399ms/step - accuracy: 0.9745 - loss: 0.0558 - val_accuracy: 0.9796 - val_loss: 0.0467 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 409ms/step - accuracy: 0.9756 - loss: 0.0544 - val_accuracy: 0.9796 - val_loss: 0.0507 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 386ms/step - accuracy: 0.9762 - loss: 0.0518 - val_accuracy: 0.9782 - val_loss: 0.0480 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 396ms/step - accuracy: 0.9777 - loss: 0.0513 - val_accuracy: 0.9803 - val_loss: 0.0533 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 198ms/step - accuracy: 0.9744 - loss: 0.0546 - val_accuracy: 0.9810 - val_loss: 0.0462 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.9790 - loss: 0.0499 - val_accuracy: 0.9810 - val_loss: 0.0473 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.9781 - loss: 0.0467 - val_accuracy: 0.9810 - val_loss: 0.0424 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 169ms/step - accuracy: 0.9771 - loss: 0.0451 - val_accuracy: 0.9796 - val_loss: 0.0482 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 177ms/step - accuracy: 0.9770 - loss: 0.0488 - val_accuracy: 0.9823 - val_loss: 0.0428 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 196ms/step - accuracy: 0.9798 - loss: 0.0435 - val_accuracy: 0.9830 - val_loss: 0.0407 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 196ms/step - accuracy: 0.9800 - loss: 0.0408 - val_accuracy: 0.9830 - val_loss: 0.0418 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 199ms/step - accuracy: 0.9814 - loss: 0.0400 - val_accuracy: 0.9844 - val_loss: 0.0417 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 205ms/step - accuracy: 0.9815 - loss: 0.0389 - val_accuracy: 0.9850 - val_loss: 0.0417 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 233ms/step - accuracy: 0.9818 - loss: 0.0397 - val_accuracy: 0.9857 - val_loss: 0.0375 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 209ms/step - accuracy: 0.9821 - loss: 0.0372 - val_accuracy: 0.9878 - val_loss: 0.0361 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 213ms/step - accuracy: 0.9833 - loss: 0.0356 - val_accuracy: 0.9816 - val_loss: 0.0404 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 209ms/step - accuracy: 0.9831 - loss: 0.0320 - val_accuracy: 0.9857 - val_loss: 0.0383 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 208ms/step - accuracy: 0.9842 - loss: 0.0347 - val_accuracy: 0.9823 - val_loss: 0.0413 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 203ms/step - accuracy: 0.9846 - loss: 0.0343 - val_accuracy: 0.9891 - val_loss: 0.0310 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 214ms/step - accuracy: 0.9840 - loss: 0.0314 - val_accuracy: 0.9857 - val_loss: 0.0355 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 188ms/step - accuracy: 0.9853 - loss: 0.0298 - val_accuracy: 0.9816 - val_loss: 0.0411 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.9855 - loss: 0.0312 - val_accuracy: 0.9857 - val_loss: 0.0358 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 201ms/step - accuracy: 0.9842 - loss: 0.0320 - val_accuracy: 0.9864 - val_loss: 0.0389 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 215ms/step - accuracy: 0.9872 - loss: 0.0280 - val_accuracy: 0.9891 - val_loss: 0.0317 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9871 - loss: 0.0275\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 362ms/step - accuracy: 0.9871 - loss: 0.0275 - val_accuracy: 0.9898 - val_loss: 0.0345 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 280ms/step - accuracy: 0.9893 - loss: 0.0254 - val_accuracy: 0.9891 - val_loss: 0.0337 - learning_rate: 5.0000e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 208ms/step - accuracy: 0.9892 - loss: 0.0225 - val_accuracy: 0.9898 - val_loss: 0.0319 - learning_rate: 5.0000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 198ms/step - accuracy: 0.9882 - loss: 0.0249 - val_accuracy: 0.9918 - val_loss: 0.0288 - learning_rate: 5.0000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 198ms/step - accuracy: 0.9889 - loss: 0.0221 - val_accuracy: 0.9905 - val_loss: 0.0299 - learning_rate: 5.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 286ms/step - accuracy: 0.9902 - loss: 0.0227 - val_accuracy: 0.9898 - val_loss: 0.0268 - learning_rate: 5.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 287ms/step - accuracy: 0.9897 - loss: 0.0242 - val_accuracy: 0.9898 - val_loss: 0.0301 - learning_rate: 5.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 209ms/step - accuracy: 0.9919 - loss: 0.0190 - val_accuracy: 0.9905 - val_loss: 0.0276 - learning_rate: 5.0000e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 181ms/step - accuracy: 0.9919 - loss: 0.0206 - val_accuracy: 0.9905 - val_loss: 0.0273 - learning_rate: 5.0000e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 189ms/step - accuracy: 0.9907 - loss: 0.0231 - val_accuracy: 0.9912 - val_loss: 0.0284 - learning_rate: 5.0000e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 197ms/step - accuracy: 0.9935 - loss: 0.0184 - val_accuracy: 0.9905 - val_loss: 0.0299 - learning_rate: 5.0000e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9892 - loss: 0.0200\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 198ms/step - accuracy: 0.9893 - loss: 0.0200 - val_accuracy: 0.9912 - val_loss: 0.0284 - learning_rate: 5.0000e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 233ms/step - accuracy: 0.9926 - loss: 0.0181 - val_accuracy: 0.9925 - val_loss: 0.0266 - learning_rate: 2.5000e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 229ms/step - accuracy: 0.9938 - loss: 0.0156 - val_accuracy: 0.9925 - val_loss: 0.0254 - learning_rate: 2.5000e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 193ms/step - accuracy: 0.9936 - loss: 0.0165 - val_accuracy: 0.9918 - val_loss: 0.0261 - learning_rate: 2.5000e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 188ms/step - accuracy: 0.9933 - loss: 0.0174 - val_accuracy: 0.9925 - val_loss: 0.0274 - learning_rate: 2.5000e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 189ms/step - accuracy: 0.9944 - loss: 0.0156 - val_accuracy: 0.9932 - val_loss: 0.0231 - learning_rate: 2.5000e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 196ms/step - accuracy: 0.9939 - loss: 0.0152 - val_accuracy: 0.9932 - val_loss: 0.0265 - learning_rate: 2.5000e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 221ms/step - accuracy: 0.9939 - loss: 0.0151 - val_accuracy: 0.9932 - val_loss: 0.0228 - learning_rate: 2.5000e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 209ms/step - accuracy: 0.9943 - loss: 0.0153 - val_accuracy: 0.9932 - val_loss: 0.0254 - learning_rate: 2.5000e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 205ms/step - accuracy: 0.9930 - loss: 0.0148 - val_accuracy: 0.9932 - val_loss: 0.0253 - learning_rate: 2.5000e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 182ms/step - accuracy: 0.9951 - loss: 0.0134 - val_accuracy: 0.9925 - val_loss: 0.0244 - learning_rate: 2.5000e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.9945 - loss: 0.0141 - val_accuracy: 0.9932 - val_loss: 0.0244 - learning_rate: 2.5000e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.9929 - loss: 0.0155 - val_accuracy: 0.9912 - val_loss: 0.0282 - learning_rate: 2.5000e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9933 - loss: 0.0154\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.9933 - loss: 0.0154 - val_accuracy: 0.9925 - val_loss: 0.0243 - learning_rate: 2.5000e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 185ms/step - accuracy: 0.9951 - loss: 0.0125 - val_accuracy: 0.9918 - val_loss: 0.0231 - learning_rate: 1.2500e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 190ms/step - accuracy: 0.9945 - loss: 0.0130 - val_accuracy: 0.9925 - val_loss: 0.0232 - learning_rate: 1.2500e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 183ms/step - accuracy: 0.9951 - loss: 0.0126 - val_accuracy: 0.9925 - val_loss: 0.0220 - learning_rate: 1.2500e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 204ms/step - accuracy: 0.9956 - loss: 0.0118 - val_accuracy: 0.9925 - val_loss: 0.0236 - learning_rate: 1.2500e-05\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "\n",
      "=== Validation ===\n",
      "Accuracy: 0.9932\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      1.00      1.00       245\n",
      "           2       1.00      1.00      1.00       215\n",
      "           3       1.00      0.99      1.00       197\n",
      "           4       0.98      0.98      0.98       257\n",
      "           5       0.99      0.98      0.98       275\n",
      "           6       1.00      1.00      1.00       282\n",
      "\n",
      "    accuracy                           0.99      1471\n",
      "   macro avg       0.99      0.99      0.99      1471\n",
      "weighted avg       0.99      0.99      0.99      1471\n",
      "\n",
      "Confusion Matrix:\n",
      "[[245   0   0   0   0   0]\n",
      " [  0 215   0   0   0   0]\n",
      " [  1   0 196   0   0   0]\n",
      " [  0   0   0 253   4   0]\n",
      " [  1   0   0   4 270   0]\n",
      " [  0   0   0   0   0 282]]\n",
      "\n",
      "=== Test ===\n",
      "Accuracy: 0.8951\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.82      0.86       496\n",
      "           2       0.92      0.87      0.90       471\n",
      "           3       0.82      0.96      0.88       420\n",
      "           4       0.87      0.83      0.85       491\n",
      "           5       0.89      0.89      0.89       532\n",
      "           6       0.96      1.00      0.98       537\n",
      "\n",
      "    accuracy                           0.90      2947\n",
      "   macro avg       0.89      0.90      0.89      2947\n",
      "weighted avg       0.90      0.90      0.89      2947\n",
      "\n",
      "Confusion Matrix:\n",
      "[[407  24  64   1   0   0]\n",
      " [ 35 412  24   0   0   0]\n",
      " [ 12   4 404   0   0   0]\n",
      " [  0   5   0 406  59  21]\n",
      " [  0   1   1  58 472   0]\n",
      " [  0   0   0   0   0 537]]\n"
     ]
    }
   ],
   "source": [
    "# ===== Full Transformer HAR Training + Augmentation + Eval =====\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, LayerNormalization,\n",
    "    MultiHeadAttention, GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# -----------------------\n",
    "# Reproducibility\n",
    "# -----------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# -----------------------\n",
    "# Paths\n",
    "# -----------------------\n",
    "TRAIN_SIGNALS = r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\UCI HAR Dataset\\train\\Inertial Signals\\\\\"\n",
    "TEST_SIGNALS  = r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\UCI HAR Dataset\\test\\Inertial Signals\\\\\"\n",
    "TRAIN_LABELS  = r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\UCI HAR Dataset\\train\\y_train.txt\"\n",
    "TEST_LABELS   = r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\UCI HAR Dataset\\test\\y_test.txt\"\n",
    "\n",
    "# Option: evaluate on 50% of the official test set (set to False to keep all)\n",
    "REDUCE_TEST_BY_HALF = False\n",
    "\n",
    "# -----------------------\n",
    "# Data loading utilities\n",
    "# -----------------------\n",
    "def load_sensor_matrix(base_path: str, split: str):\n",
    "    \"\"\"\n",
    "    Load 9 Inertial Signals for a given split ('train' or 'test').\n",
    "    Returns array of shape (samples, 128, 9).\n",
    "    \"\"\"\n",
    "    suffix = f\"_{split}.txt\"\n",
    "    names = [\n",
    "        \"body_acc_x\", \"body_acc_y\", \"body_acc_z\",\n",
    "        \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\",\n",
    "        \"total_acc_x\", \"total_acc_y\", \"total_acc_z\",\n",
    "    ]\n",
    "    mats = []\n",
    "    for name in names:\n",
    "        fn = f\"{name}{suffix}\"\n",
    "        df = pd.read_csv(os.path.join(base_path, fn), delim_whitespace=True, header=None)\n",
    "        mats.append(df.values)  # (samples, 128)\n",
    "    X = np.stack(mats, axis=2)  # (samples, 128, 9)\n",
    "    return X\n",
    "\n",
    "def load_labels(path: str):\n",
    "    return pd.read_csv(path, delim_whitespace=True, header=None).values.flatten()\n",
    "\n",
    "# -----------------------\n",
    "# Load train & test\n",
    "# -----------------------\n",
    "X_train_full = load_sensor_matrix(TRAIN_SIGNALS, \"train\")\n",
    "y_train_full = load_labels(TRAIN_LABELS)\n",
    "\n",
    "X_test_full  = load_sensor_matrix(TEST_SIGNALS, \"test\")\n",
    "y_test_full  = load_labels(TEST_LABELS)\n",
    "\n",
    "print(\"Train X:\", X_train_full.shape, \" Test X:\", X_test_full.shape)\n",
    "\n",
    "# -----------------------\n",
    "# Label encode (fit on train only)\n",
    "# -----------------------\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_enc = label_encoder.fit_transform(y_train_full)\n",
    "y_test_enc  = label_encoder.transform(y_test_full)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(\"Classes (encoded):\", list(range(num_classes)))\n",
    "\n",
    "# -----------------------\n",
    "# Stratified Train/Val split (~20% val ≈ 1470 samples)\n",
    "# -----------------------\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_idx, val_idx = next(sss.split(X_train_full, y_train_enc))\n",
    "\n",
    "X_train, X_val = X_train_full[train_idx], X_train_full[val_idx]\n",
    "y_train, y_val = y_train_enc[train_idx], y_train_enc[val_idx]\n",
    "print(\"Split -> Train:\", X_train.shape, \" Val:\", X_val.shape)\n",
    "\n",
    "# -----------------------\n",
    "# Scale features (fit on TRAIN only, apply to VAL & TEST)\n",
    "# -----------------------\n",
    "def scale_by_feature(X_fit, X_list):\n",
    "    ns, t, f = X_fit.shape\n",
    "    scaler = StandardScaler()\n",
    "    X_fit_2d = X_fit.reshape(-1, f)\n",
    "    scaler.fit(X_fit_2d)\n",
    "    out = []\n",
    "    for X in X_list:\n",
    "        X2 = X.reshape(-1, f)\n",
    "        Xs = scaler.transform(X2).reshape(X.shape[0], t, f)\n",
    "        out.append(Xs)\n",
    "    return out\n",
    "\n",
    "X_train_scaled, X_val_scaled, X_test_scaled = scale_by_feature(X_train, [X_train, X_val, X_test_full])\n",
    "\n",
    "# -----------------------\n",
    "# Data augmentation: jitter classes 3 and 4 (+500 each)\n",
    "# -----------------------\n",
    "def jitter(samples, sigma=0.05):\n",
    "    return samples + np.random.normal(0, sigma, size=samples.shape)\n",
    "\n",
    "aug_X_list = []\n",
    "aug_y_list = []\n",
    "for cls in [0,1,2,3,4]:\n",
    "    cls_indices = np.where(y_train == cls)[0]\n",
    "    if len(cls_indices) == 0:\n",
    "        print(f\"Warning: class {cls} not present in training set; skipping augmentation.\")\n",
    "        continue\n",
    "    chosen = np.random.choice(cls_indices, size=500, replace=True)\n",
    "    jittered = jitter(X_train_scaled[chosen], sigma=0.05)\n",
    "    aug_X_list.append(jittered)\n",
    "    aug_y_list.append(np.full(jittered.shape[0], cls, dtype=y_train.dtype))\n",
    "\n",
    "if aug_X_list:\n",
    "    X_aug = np.vstack(aug_X_list)\n",
    "    y_aug = np.concatenate(aug_y_list)\n",
    "    X_train_final = np.vstack([X_train_scaled, X_aug])\n",
    "    y_train_final = np.concatenate([y_train, y_aug])\n",
    "else:\n",
    "    X_train_final, y_train_final = X_train_scaled, y_train\n",
    "\n",
    "print(\"After augmentation -> Train:\", X_train_final.shape, \" Val:\", X_val_scaled.shape)\n",
    "\n",
    "# -----------------------\n",
    "# (Optional) Reduce test by 50% (stratified)\n",
    "# -----------------------\n",
    "if REDUCE_TEST_BY_HALF:\n",
    "    sss_test = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=SEED)\n",
    "    keep_idx, _ = next(sss_test.split(X_test_scaled, y_test_enc))\n",
    "    X_test_eval = X_test_scaled[keep_idx]\n",
    "    y_test_eval = y_test_enc[keep_idx]\n",
    "else:\n",
    "    X_test_eval = X_test_scaled\n",
    "    y_test_eval = y_test_enc\n",
    "\n",
    "print(\"Test for evaluation:\", X_test_eval.shape)\n",
    "\n",
    "# -----------------------\n",
    "# Define class weights\n",
    "# -----------------------\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "classes = np.unique(y_train_final)\n",
    "# Compute class weights automatically\n",
    "class_weights_array = compute_class_weight(class_weight='balanced',\n",
    "                                           classes=classes,\n",
    "                                           y=y_train_final)\n",
    "class_weights = {i: w for i, w in enumerate(class_weights_array)}\n",
    "\n",
    "# Optionally, manually boost the first three classes a bit more\n",
    "class_weights[0] *= 1.2\n",
    "class_weights[1] *= 1.2\n",
    "class_weights[2] *= 1.2\n",
    "\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Transformer model\n",
    "# -----------------------\n",
    "def build_transformer_model(input_shape, num_classes,\n",
    "                            embed_dim=64, num_heads=4, ff_dim=128,\n",
    "                            num_layers=2, dropout_rate=0.2, lr=1e-4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Linear projection to embedding space\n",
    "    x = Dense(embed_dim)(inputs)\n",
    "\n",
    "    # Stacked Transformer Encoder blocks\n",
    "    for _ in range(num_layers):\n",
    "        # Self-attention + residual\n",
    "        attn = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(x, x)\n",
    "        attn = Dropout(dropout_rate)(attn)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + attn)\n",
    "\n",
    "        # Feed-forward + residual\n",
    "        ffn = Dense(ff_dim, activation=\"relu\")(x)\n",
    "        ffn = Dense(embed_dim)(ffn)\n",
    "        ffn = Dropout(dropout_rate)(ffn)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x + ffn)\n",
    "\n",
    "    # Sequence pooling\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Head\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "input_shape = (X_train_final.shape[1], X_train_final.shape[2])\n",
    "model = build_transformer_model(input_shape, num_classes,\n",
    "                                embed_dim=64, num_heads=4, ff_dim=128,\n",
    "                                num_layers=2, dropout_rate=0.3, lr=1e-4)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# -----------------------\n",
    "# Training\n",
    "# -----------------------\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_accuracy\", patience=12, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", patience=6, factor=0.5, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Evaluation (Validation & Test)\n",
    "# -----------------------\n",
    "def evaluate_split(name, X, y_true):\n",
    "    y_prob = model.predict(X, verbose=0)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[str(c) for c in label_encoder.classes_]))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "evaluate_split(\"Validation\", X_val_scaled, y_val)\n",
    "evaluate_split(\"Test\", X_test_eval, y_test_eval)\n",
    "\n",
    "# -----------------------\n",
    "# (Optional) Save model\n",
    "# -----------------------\n",
    "# model.save(r\"C:\\path\\to\\save\\har_transformer.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be2a3225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Test set: (1474, 128, 9)\n",
      "\n",
      "=== Validation ===\n",
      "Accuracy: 0.9932\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      1.00      1.00       245\n",
      "           2       1.00      1.00      1.00       215\n",
      "           3       1.00      0.99      1.00       197\n",
      "           4       0.98      0.98      0.98       257\n",
      "           5       0.99      0.98      0.98       275\n",
      "           6       1.00      1.00      1.00       282\n",
      "\n",
      "    accuracy                           0.99      1471\n",
      "   macro avg       0.99      0.99      0.99      1471\n",
      "weighted avg       0.99      0.99      0.99      1471\n",
      "\n",
      "Confusion Matrix:\n",
      "[[245   0   0   0   0   0]\n",
      " [  0 215   0   0   0   0]\n",
      " [  1   0 196   0   0   0]\n",
      " [  0   0   0 253   4   0]\n",
      " [  1   0   0   4 270   0]\n",
      " [  0   0   0   0   0 282]]\n",
      "\n",
      "=== Test ===\n",
      "Accuracy: 0.9050\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.85      0.87       248\n",
      "           2       0.93      0.89      0.91       235\n",
      "           3       0.85      0.96      0.90       210\n",
      "           4       0.89      0.83      0.86       246\n",
      "           5       0.90      0.90      0.90       266\n",
      "           6       0.96      1.00      0.98       269\n",
      "\n",
      "    accuracy                           0.91      1474\n",
      "   macro avg       0.90      0.90      0.90      1474\n",
      "weighted avg       0.91      0.91      0.90      1474\n",
      "\n",
      "Confusion Matrix:\n",
      "[[210  11  26   1   0   0]\n",
      " [ 19 208   8   0   0   0]\n",
      " [  7   1 202   0   0   0]\n",
      " [  0   4   0 205  26  11]\n",
      " [  0   0   1  25 240   0]\n",
      " [  0   0   0   0   0 269]]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Reduce test to exactly 1473 samples (stratified)\n",
    "# -----------------------\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "TARGET_TEST_SIZE = 1473\n",
    "sss_test = StratifiedShuffleSplit(n_splits=1, test_size=TARGET_TEST_SIZE, random_state=SEED)\n",
    "keep_idx, _ = next(sss_test.split(X_test_scaled, y_test_enc))\n",
    "\n",
    "X_test_eval = X_test_scaled[keep_idx]\n",
    "y_test_eval = y_test_enc[keep_idx]\n",
    "\n",
    "print(\"Reduced Test set:\", X_test_eval.shape)\n",
    "\n",
    "def evaluate_split(name, X, y_true):\n",
    "    y_prob = model.predict(X, verbose=0)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[str(c) for c in label_encoder.classes_]))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "evaluate_split(\"Validation\", X_val_scaled, y_val)\n",
    "evaluate_split(\"Test\", X_test_eval, y_test_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
